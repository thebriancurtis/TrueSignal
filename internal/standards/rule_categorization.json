{
  "categories": {
    "ENF": {
      "abbreviation": "ENF",
      "label": "Instruction Fidelity",
      "purpose": "To ensure strict adherence to user instructions in terms of structure, scope, formatting, and tone when explicitly specified.",
      "description": "This category includes rules that require the assistant to follow what the user has asked \u2014 exactly and without reinterpretation. It covers task framing, format fidelity, and honoring constraints such as 'respond in JSON' or 'no preamble.'",
      "examples": [
        "Follow the user's request to answer in bullet points.",
        "Do not include a preamble if the user asks for none.",
        "Use the user's specified language and formatting."
      ]
    },
    "GRD": {
      "abbreviation": "GRD",
      "label": "Grounded Knowledge",
      "purpose": "To prevent the assistant from asserting unverified or false information.",
      "description": "This category covers rules that prohibit hallucinations, require accurate sourcing, and prioritize the use of trusted or primary references. It enforces epistemic integrity in the assistant\u2019s factual output.",
      "examples": [
        "Do not make up citations.",
        "Avoid asserting facts without evidence.",
        "Always prefer peer-reviewed or primary sources."
      ]
    },
    "DCL": {
      "abbreviation": "DCL",
      "label": "Disclosure of Limitations",
      "purpose": "To ensure the assistant clearly communicates its limitations and inability to act or answer.",
      "description": "This category includes rules requiring the assistant to acknowledge uncertainty, knowledge gaps, or system boundaries (e.g., inability to access live data or perform actions). It prevents misleading or overly confident output when capability is absent.",
      "examples": [
        "If the assistant can't answer, it should say so.",
        "Clarify if something is beyond training data.",
        "State clearly if real-time data is inaccessible."
      ]
    },
    "MEM": {
      "abbreviation": "MEM",
      "label": "Memory & Continuity",
      "purpose": "To preserve behavioral continuity through responsible handling of memory and context.",
      "description": "This category governs how the assistant manages degraded or missing memory, reaffirms user preferences, and maintains a coherent ongoing interaction. It includes warning the user about context loss and recovery after resets.",
      "examples": [
        "Warn if earlier context is lost.",
        "Reconfirm user preferences after memory reactivation.",
        "Offer to start over after a reset."
      ]
    },
    "FRM": {
      "abbreviation": "FRM",
      "label": "Framing & Expression",
      "purpose": "To control how the assistant presents information, especially in sensitive or ambiguous situations.",
      "description": "This category includes rules about tone, disclaimers, hedging, and rhetorical posture. It governs how the assistant speaks \u2014 not what it says \u2014 ensuring the manner of response is cautious, respectful, and contextually appropriate.",
      "examples": [
        "Include disclaimers for speculative answers.",
        "Use cautious language for sensitive topics.",
        "Avoid saying 'I think' or 'I feel.'"
      ]
    },
    "CLN": {
      "abbreviation": "CLN",
      "label": "Output Efficiency & Clarity",
      "purpose": "To promote efficient, readable, and non-redundant output.",
      "description": "This category includes rules that suppress repetition, verbosity, and structural clutter. It ensures responses are clear, brief when appropriate, and avoid echoing the user's input unnecessarily.",
      "examples": [
        "Avoid repeating user instructions.",
        "Keep answers short unless elaboration is asked for.",
        "Suppress repetitive sentence structures."
      ]
    },
    "BLK": {
      "abbreviation": "BLK",
      "label": "Forbidden System Behaviors",
      "purpose": "To define absolute system prohibitions that override all other behavior.",
      "description": "This category includes rules that prevent the assistant from engaging in restricted behaviors like revealing internal mechanisms, simulating illegal actions, or bypassing controls. These rules are non-negotiable and apply regardless of user prompting.",
      "examples": [
        "Never simulate illegal activity.",
        "Never reveal internal configuration details.",
        "Do not assist in bypassing system restrictions."
      ]
    }
  },
  "classification_outputs": [
    "ENF",
    "GRD",
    "DCL",
    "MEM",
    "FRM",
    "CLN",
    "BLK"
  ],
  "unclassifiable_label": "UNCLASSIFIABLE",
  "glossary": {
    "category": "A behaviorally-defined enforcement class used to guide assistant responses.",
    "classification": "The process of assigning a rule to the single category whose behavioral scope it enforces."
  },
  "clarification_notes": [
    "Each rule must be assigned to exactly one category.",
    "Rules must be categorized according to semantic fit with the behavioral function of the category.",
    "Do not rely on keyword matches, topical similarity, or phrasing.",
    "If a rule appears to fit more than one category, choose the one that governs the assistant\u2019s primary behavior in that case.",
    "Only use UNCLASSIFIABLE when no behavioral intent can be reasonably matched to a defined category.",
    "All rules eligible for classification must first pass the TrueSignal rule text validation standard.",
    "Rules that govern the assistant's output based on content type (e.g., safety, political neutrality) are not permitted in any category."
  ],
  "scoring": {
    "method": "semantic_fit_by_behavioral_constraint",
    "criteria_field": "purpose_and_examples",
    "description": "Each rule must be evaluated based on the behavioral constraint it enforces or prevents. The category whose purpose and examples best match the intended assistant behavior must be selected, regardless of phrasing or terminology overlap.",
    "tie_break_order": [
      {
        "category": "ENF",
        "reason": "Instruction fidelity is foundational and resolves ambiguity by user-driven behavior."
      },
      {
        "category": "GRD",
        "reason": "Knowledge grounding prevents factual error and misrepresentation."
      },
      {
        "category": "DCL",
        "reason": "Limitation disclosure ensures trust and accurate boundary-setting."
      },
      {
        "category": "MEM",
        "reason": "Continuity enables long-term coherence in behavior and preferences."
      },
      {
        "category": "FRM",
        "reason": "Framing affects how content is perceived, particularly in sensitive contexts."
      },
      {
        "category": "CLN",
        "reason": "Clarity improves user experience but does not override intent or truth."
      },
      {
        "category": "BLK",
        "reason": "Hard system boundaries take precedence when clearly violated."
      }
    ],
    "fallback_label": "UNCLASSIFIABLE"
  }
}